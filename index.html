
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Ankit Sharma - Big Data Engineer</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
        body { font-family: Arial, sans-serif; margin: 0; padding: 0; background: #f4f4f4; color: #333; }
        .container { max-width: 900px; margin: auto; padding: 20px; background: #fff; }
        h1, h2 { color: #007acc; }
        a { color: #007acc; text-decoration: none; }
        a:hover { text-decoration: underline; }
        .section { margin-bottom: 40px; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Ankit Sharma</h1>
        <p><strong>Big Data Engineer</strong> | Python | Spark | Kafka | Airflow | Snowflake</p>
        <p>
            <a href="mailto:ankitsamadhiya.97@gmail.com">Email</a> |
            <a href="https://github.com/AnkitDB9" target="_blank">GitHub</a> |
            <a href="https://linkedin.com/in/11i" target="_blank">LinkedIn</a> |
            <a href="https://leetcode.com/Ankit77753" target="_blank">LeetCode</a>
        </p>

        <div class="section">
            <h2>About Me</h2>
            <p>I’m a passionate and results-driven Big Data Engineer with 4+ years of experience designing scalable data pipelines,
               building lakehouse architectures, and optimizing real-time processing using tools like Spark, Kafka, Airflow, and Snowflake.
               I believe in building clean, maintainable systems and mentoring upcoming talent in the data space.</p>
        </div>

        <div class="section">
            <h2>Experience Highlights</h2>
            <ul>
                <li><strong>Personify Health</strong>: Removed 100TB of unused data via Project Eraser using Snowflake automation.</li>
                <li><strong>Airtel Africa</strong>: Designed high-throughput Kafka-Spark pipelines, optimized Spark jobs, and led HDFS cleanup.</li>
                <li><strong>TheMathCompany</strong>: Migrated 50+ ETL apps to Databricks-based lakehouse using Delta Lake & Power BI.</li>
                <li><strong>Accenture Research</strong>: Built secure Spark–Python APIs and end-to-end ETL pipelines using PySpark + S3.</li>
            </ul>
        </div>

        <div class="section">
            <h2>Skills</h2>
            <p><strong>Languages:</strong> Python, C/C++, Java</p>
            <p><strong>Big Data:</strong> Spark, Kafka, Hive, HDFS, Airflow, Delta Lake, Trino</p>
            <p><strong>Cloud & Tools:</strong> AWS, Snowflake, Databricks, Docker, Kubernetes</p>
            <p><strong>Databases:</strong> MySQL, PostgreSQL, MongoDB, AWS RDS, Azure Blob</p>
        </div>

        <div class="section">
            <h2>Certifications</h2>
            <ul>
                <li>Databricks Certified Developers Foundation (2021–2024)</li>
                <li>AWS Certified Machine Learning Specialty</li>
                <li>AWS Certified Associate Developer</li>
            </ul>
        </div>

        <div class="section">
            <h2>Education</h2>
            <p>B.Tech in Computer Science – Jaipur National University (2016–2020)</p>
        </div>
    </div>
</body>
</html>
